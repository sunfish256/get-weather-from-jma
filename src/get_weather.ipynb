{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05890d32-2dd0-49f5-98aa-848e5e534900",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sunfish256/get-weather-from-jma/blob/main/src/get_weather.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a8ef8-248b-4b49-a54d-6469bed1bd44",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 200%\">**日ごとの過去気象データを取得する関数**</span>  \n",
    "\n",
    "このスクリプトでは東京（気象台）を例とする。  \n",
    "その他の観測地点の気象データを取得する場合は、\n",
    "[気象庁｜過去の気象データ検索](https://www.data.jma.go.jp/obd/stats/etrn/index.php?prec_no=44&block_no=47662&year=2019&month=02&day=01&view=p1)\n",
    "にアクセスし、「地点の選択」を実行する。  \n",
    "その後、URLから位置情報（**prec_no**と**block_no**）を取得して、loc_info引数を書き変える。  \n",
    "また、prec_noの直前が**daily_<font color=\"Red\">s</font>1.php**（気象台・観測所データ）と**daily_<font color=\"Red\">a</font>1.php**（アメダスデータ）のどちらであるかも要注意。  \n",
    "アメダスデータの場合、コメントアウトされている最終セルを代わりに実行する。  \n",
    "\n",
    "観測地点によっては観測項目の違いがあるかもしれないため、エラーの際は\n",
    "[気象庁｜過去の気象データ検索｜日ごとの値](https://www.data.jma.go.jp/obd/stats/etrn/view/daily_s1.php?prec_no=44&block_no=47662&year=2023&month=1&day=01&view=p1)\n",
    "（リンク先は東京の値）の表の項目が一致しているかを確認する。  \n",
    "一致していなければscraping関数のdata_list.append部分と、create_csv関数のfields変数を書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0458b4-1bae-4ad3-a8c2-dd0cc87b3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import re\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de9d6d-b4d9-4967-94a3-3ac017320d66",
   "metadata": {},
   "source": [
    "入力項目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add88b0e-6bc6-4f60-8ff6-60a86a27795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力先パス\n",
    "csv_path = 'output_sample.csv'\n",
    "# データ取得開始・終了日\n",
    "start_date = datetime.date(2023, 1, 1)\n",
    "end_date = datetime.date.today()\n",
    "# 観測地点のURL情報\n",
    "loc_info = 'daily_s1.php?prec_no=44&block_no=47662&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05109f40-8df3-4cff-8510-8c70d7a6f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2float(weather_data):\n",
    "    if weather_data is None:\n",
    "        return np.nan\n",
    "    # 表データ内に\"])半角スペース\"が混入するケースがあったので除去\n",
    "    else:\n",
    "        value = re.sub(r'[\\]) ]', '', weather_data)\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        if value == '--':\n",
    "            return 0\n",
    "        if value == '///':\n",
    "            return np.nan\n",
    "        else:\n",
    "            raise ValueError(f'Unexpected value \"{weather_data}\".')\n",
    "\n",
    "\n",
    "def str2str(weather_data):\n",
    "    if weather_data is None:\n",
    "        return np.nan\n",
    "    # 表データ内に\"])半角スペース\"が混入するケースがあったので除去\n",
    "    else:\n",
    "        value = re.sub(r'[\\]) ]', '', weather_data)\n",
    "    if value == '--':\n",
    "        return 0\n",
    "    if value == '///':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "def scraping(url, date):\n",
    "\n",
    "    # 気象データのページを取得\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html)\n",
    "    trs = soup.find('table', { 'class' : 'data2_s' })\n",
    "\n",
    "    data_list = []\n",
    "    data_list_per_month = []\n",
    "\n",
    "    # table の中身を取得\n",
    "    for tr in trs.findAll('tr'):\n",
    "        tds = tr.findAll('td')\n",
    "\n",
    "        if tds:\n",
    "            data_list.append(f'{date.year}-{date.month}-{tds[0].string}')\n",
    "            data_list.append(str2float(tds[1].string))\n",
    "            data_list.append(str2float(tds[2].string))\n",
    "            data_list.append(str2float(tds[3].string))\n",
    "            data_list.append(str2float(tds[4].string))\n",
    "            data_list.append(str2float(tds[5].string))\n",
    "            data_list.append(str2float(tds[6].string))\n",
    "            data_list.append(str2float(tds[7].string))\n",
    "            data_list.append(str2float(tds[8].string))\n",
    "            data_list.append(str2float(tds[9].string))\n",
    "            data_list.append(str2float(tds[10].string))\n",
    "            data_list.append(str2float(tds[11].string))\n",
    "            data_list.append(str2float(tds[12].string))\n",
    "            data_list.append(str2str(tds[13].string))\n",
    "            data_list.append(str2float(tds[14].string))\n",
    "            data_list.append(str2str(tds[15].string))\n",
    "            data_list.append(str2float(tds[16].string))\n",
    "            data_list.append(str2float(tds[17].string))\n",
    "            data_list.append(str2float(tds[18].string))\n",
    "            data_list.append(str2str(tds[19].string))\n",
    "            data_list.append(str2str(tds[20].string))\n",
    "\n",
    "            data_list_per_month.append(data_list)\n",
    "            data_list = []\n",
    "\n",
    "    return data_list_per_month\n",
    "\n",
    "\n",
    "def create_csv(csv_path, start_date, end_date, loc_info):\n",
    "    # CSV の列\n",
    "    fields = [\n",
    "        '年月日',\n",
    "        '気圧_現地', '気圧_海面',\n",
    "        '降水量_合計', '降水量_1時間最大', '降水量_10分間最大',\n",
    "        '気温_平均', '気温_最高', '気温_最低',\n",
    "        '湿度_平均', '湿度_最小',\n",
    "        '風速_平均', '風速_最大', '風向_最大', '風速_最大瞬間', '風向_最大瞬間',\n",
    "        '日照時間',\n",
    "        '降雪_合計', '積雪_最深',\n",
    "        '天気_昼', '天気_夜'\n",
    "    ]\n",
    "\n",
    "    with open(csv_path, 'w', encoding='utf-8-sig') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        writer.writerow(fields)\n",
    "\n",
    "        date = start_date\n",
    "        while date <= end_date:\n",
    "            print(f'Getiing data for {date}')\n",
    "            # URLを指定：観測地点の日ごとの気象データ（月別）\n",
    "            url = 'https://www.data.jma.go.jp/obd/stats/etrn/view/' \\\n",
    "                  + loc_info + \\\n",
    "                  f'year={date.year}&month={date.month}&day=&view='\n",
    "\n",
    "            data_list_per_month = scraping(url, date)\n",
    "\n",
    "            for d in data_list_per_month:\n",
    "                writer.writerow(d)\n",
    "\n",
    "            date += relativedelta(months=1)\n",
    "            \n",
    "    print('Complete!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_csv(csv_path, start_date, end_date, loc_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eb0820-e332-4e39-847e-abe0b26aec55",
   "metadata": {},
   "source": [
    "<br>**以下、アメダスの場合**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b8259-d7d0-4158-bee6-20dff40b2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def str2float(weather_data):\n",
    "#     if weather_data is None:\n",
    "#         return np.nan\n",
    "#     # 表データ内に\"])半角スペース\"が混入するケースがあったので除去\n",
    "#     else:\n",
    "#         value = re.sub(r'[\\]) ]', '', weather_data)\n",
    "#     try:\n",
    "#         return float(value)\n",
    "#     except:\n",
    "#         if value == '--':\n",
    "#             return 0\n",
    "#         if value == '///':\n",
    "#             return np.nan\n",
    "#         else:\n",
    "#             raise ValueError(f'Unexpected value \"{weather_data}\".')\n",
    "\n",
    "\n",
    "# def str2str(weather_data):\n",
    "#     if weather_data is None:\n",
    "#         return np.nan\n",
    "#     # 表データ内に\"])半角スペース\"が混入するケースがあったので除去\n",
    "#     else:\n",
    "#         value = re.sub(r'[\\]) ]', '', weather_data)\n",
    "#     if value == '--':\n",
    "#         return 0\n",
    "#     if value == '///':\n",
    "#         return np.nan\n",
    "#     else:\n",
    "#         return value\n",
    "\n",
    "\n",
    "# def scraping(url, date):\n",
    "\n",
    "#     # 気象データのページを取得\n",
    "#     html = urllib.request.urlopen(url).read()\n",
    "#     soup = BeautifulSoup(html)\n",
    "#     trs = soup.find('table', { 'class' : 'data2_s' })\n",
    "\n",
    "#     data_list = []\n",
    "#     data_list_per_month = []\n",
    "\n",
    "#     # table の中身を取得\n",
    "#     for tr in trs.findAll('tr'):\n",
    "#         tds = tr.findAll('td')\n",
    "\n",
    "#         if tds:\n",
    "#             data_list.append(f'{date.year}-{date.month}-{tds[0].string}')\n",
    "#             data_list.append(str2float(tds[1].string))\n",
    "#             data_list.append(str2float(tds[2].string))\n",
    "#             data_list.append(str2float(tds[3].string))\n",
    "#             data_list.append(str2float(tds[4].string))\n",
    "#             data_list.append(str2float(tds[5].string))\n",
    "#             data_list.append(str2float(tds[6].string))\n",
    "#             data_list.append(str2float(tds[7].string))\n",
    "#             data_list.append(str2float(tds[8].string))\n",
    "#             data_list.append(str2float(tds[9].string))\n",
    "#             data_list.append(str2float(tds[10].string))\n",
    "#             data_list.append(str2str(tds[11].string))\n",
    "#             data_list.append(str2float(tds[12].string))\n",
    "#             data_list.append(str2str(tds[13].string))\n",
    "#             data_list.append(str2str(tds[14].string))\n",
    "#             data_list.append(str2float(tds[15].string))\n",
    "#             data_list.append(str2float(tds[16].string))\n",
    "#             data_list.append(str2float(tds[17].string))\n",
    "\n",
    "#             data_list_per_month.append(data_list)\n",
    "#             data_list = []\n",
    "\n",
    "#     return data_list_per_month\n",
    "\n",
    "\n",
    "# def create_csv(csv_path, start_date, end_date, loc_info):\n",
    "#     # CSV の列\n",
    "#     fields = [\n",
    "#         '年月日',\n",
    "#         '降水量_合計', '降水量_最大_60min', '降水量_最大_10min',\n",
    "#         '気温_平均', '気温_最高', '気温_最低',\n",
    "#         '湿度_平均', '湿度_最小',\n",
    "#         '風速_平均', '風速_最大', '風向_最大', '風速_最大瞬間', '風向_最大瞬間', '最多風向',\n",
    "#         '日照時間',\n",
    "#         '降雪_合計', '積雪_最深',\n",
    "#     ]\n",
    "\n",
    "#     with open(csv_path, 'w', encoding='utf-8-sig') as f:\n",
    "#         writer = csv.writer(f, lineterminator='\\n')\n",
    "#         writer.writerow(fields)\n",
    "\n",
    "#         date = start_date\n",
    "#         while date <= end_date:\n",
    "#             print(f'Getiing data for {date}')\n",
    "#             # URLを指定：観測地点の日ごとの気象データ（月別）\n",
    "#             url = 'https://www.data.jma.go.jp/obd/stats/etrn/view/' \\\n",
    "#                   + loc_info + \\\n",
    "#                   f'year={date.year}&month={date.month}&day=&view='\n",
    "\n",
    "#             data_list_per_month = scraping(url, date)\n",
    "\n",
    "#             for d in data_list_per_month:\n",
    "#                 writer.writerow(d)\n",
    "\n",
    "#             date += relativedelta(months=1)\n",
    "\n",
    "#     print('Complete!')\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     create_csv(csv_path, start_date, end_date, loc_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
